{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs Tweet Project Wrangle Report\n",
    "\n",
    "The data we're working on in this project is from WeRateDog's tweets (@dogrates) in the timespan Nov 15, 2015 to Aug 1, 2017.\n",
    "\n",
    "## Gathering\n",
    "Our data comes from three different sources. Below are the sources and how I gathered data from each of them.\n",
    "\n",
    "> **Note**  \n",
    "The project was conducted using Jupyter Notebook and pandas version 1.4.2\n",
    "\n",
    "### 1. WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)\n",
    "\n",
    "* A `csv` file from @dog_rates twitter archives was provided. \n",
    "* It was downloaded manually and loaded into a pandas dataframe using `pandas.read_csv`\n",
    "* The file contained tweet data such as the tweet id, the tweet, url, and timestamp.\n",
    "\n",
    "### 2. Tweet image prediction (image_predictions.tsv)\n",
    "\n",
    "* A url to a `tsv` file was provided. \n",
    "* The file contained data on dog breed predictions based on images attached with the tweet.  \n",
    "* The file was accessed using the `requests` library and its contents written into a `tsv` file.    \n",
    "* The file was loaded into `pandas` using `pandas.read_csv` with a tab `\\t` as the delimiter  \n",
    "\n",
    "### 3. Extra tweet data via Tweepy (tweet_json.txt)\n",
    "\n",
    "* More information on number of likes, quotes, replies, and retweets was needed.\n",
    "* They were extracted using a Twitter Developer account and Tweepy library\n",
    "- The tweet ids in our first file and the tweet field `public_metrics` were used to obtain them\n",
    "* The extracted data was stored in a txt file and later converted into a dataframe using `pd.json_normalize()` \n",
    "\n",
    "\n",
    "## Assessing and Cleaning\n",
    "Both visual and programmatic assessing were conducted.  \n",
    "A number of issues were identified during the assessing stage.   \n",
    "Below are the issues identified and how they were fixed.   \n",
    "Note that copies of the data were made before cleaning was conducted.\n",
    "\n",
    "\n",
    "### Quality issues\n",
    "\n",
    "1. **Retweets in the data** -> **Delete the retweets**\n",
    "* We only needed original tweets so the retweets(rows) and retweet-related columns were deleted\n",
    "\n",
    "2. **Rows with missing Data** -> **Delete the rows**\n",
    "* Tweets that had been deleted yielded rows full of `NaN` in the last dataframe. These rows were dropped.\n",
    "\n",
    "3. **Invalid data** -> **Extract correct data**\n",
    "* `very` and other non-names appeared as dog names and the string `None` a value representing unavailable data.\n",
    "* Incorrect ratings were also present\n",
    "* The correct was data extracted using regex and `None` strings replaced with `np.nan`\n",
    "\n",
    "4. **Wrong data types** -> **Change to correct dtypes** \n",
    "* `astype()` was used to handle most conversions\n",
    "\n",
    "5. **`Noise` in `source` column** -> **Useful data was extracted**\n",
    "* Useful data was somewhat hidden among lots of unuseful information.  \n",
    "  The useful data was extracted from the `noise`\n",
    "\n",
    "6. **Long column names** -> **Shorten the names** \n",
    "* Unnecessary prefixes were removed using `.replace()`\n",
    "\n",
    "7. **Inconsistent column names** -> **Rename Columns**\n",
    "* Columns identifying tweet ids in different dataframes had varying names.  \n",
    "  One of them was renamed to match the other. \n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "1. **Same variable in separate columns** -> **Merged into one column** \n",
    "* The dog stages, reply status, and best dog predictions were spread over a number of columns.\n",
    "* The dog stages were reextracted using regex and put into one column and the four separate columns deleted\n",
    "* The best prediction of an actual dog breed was extracted them into a single column\n",
    "* A new column was created that gives reply status ie whether a tweet is a reply or not and the two redundant columns deleted.\n",
    "\n",
    "\n",
    "2. **Same observation in separate dataframes** -> **Merged dataframes** \n",
    "* `we_rate_dogs` and `extra_tweet_data` dataframes contained related info\n",
    "* The two dataframes were merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
